{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ewd(x, y, nbins):  \n",
    "    \"\"\"Apply Equal Width Discretization (EWD) to the training data to determine variances\"\"\"\n",
    "    \n",
    "    df_train = np.array(np.c_[x,y])\n",
    "    xdata = np.array(copy(df_train[:,0]))\n",
    "    xdata = np.squeeze(xdata)\n",
    "    df_train = df_train[np.argsort(df_train[:,0])]\n",
    "    cuts1, cuts2 = pd.cut(xdata, nbins, retbins=True)\n",
    "    \n",
    "    return df_train, cuts1, cuts2\n",
    "\n",
    "def binned_statistics(x,y, nbins):\n",
    "    \"\"\"Find the mean, variance and number of counts within the bins described by ewd\"\"\"\n",
    "    \n",
    "    df_train, cuts1, cuts2 = ewd(x,y, nbins)\n",
    "    mean, edges, binnum = scipy.stats.binned_statistic(df_train[:,0], df_train[:,1], statistic='mean', bins=cuts2)\n",
    "    var, edges, binnum = scipy.stats.binned_statistic(df_train[:,0], df_train[:,1], statistic='std', bins=cuts2)\n",
    "    count, edges, binnum = scipy.stats.binned_statistic(df_train[:,0], df_train[:,1], statistic='count', bins=cuts2)\n",
    "    \n",
    "    return mean, var, count\n",
    "\n",
    "def vectorize_variance(x,y, nbins):\n",
    "    \"\"\"Apply the binned variances to the original training data\"\"\"\n",
    "    \n",
    "    df_train, cuts1, cuts2 = ewd(x,y, nbins)\n",
    "    mean, std, count = binned_statistics(x,y, nbins)\n",
    "    variance=[]\n",
    "    m=0\n",
    "    i=0\n",
    "    while i<len(count):\n",
    "        maximum = count[i]\n",
    "\n",
    "        while m < maximum:\n",
    "            variance.append(std[i])\n",
    "            m+=1\n",
    "        else:\n",
    "            m=0\n",
    "            i+=1\n",
    "    return np.array(variance)\n",
    "\n",
    "def vectorize_mean(x,y, nbins):\n",
    "    \n",
    "    df_train, cuts1, cuts2 = ewd(x,y, nbins)\n",
    "    mean, std, count = binned_statistics(x,y,nbins)\n",
    "    means=[]\n",
    "    m=0\n",
    "    i=0\n",
    "    while i<len(count):\n",
    "        maximum = count[i]\n",
    "\n",
    "        while m < maximum:\n",
    "            means.append(mean[i])\n",
    "            m+=1\n",
    "        else:\n",
    "            m=0\n",
    "            i+=1\n",
    "    return np.array(means)\n",
    "\n",
    "def get_mean_pseudodata(x,y, nbins):\n",
    "    df_train, cuts1, cuts2 = ewd(x, y, nbins)\n",
    "    mean, std, count = binned_statistics(x,y,nbins)\n",
    "    meanvector = vectorize_mean(x,y,nbins)\n",
    "    stdvector = vectorize_variance(x,y,nbins)\n",
    "    return mean, std, meanvector, stdvector\n",
    "\n",
    "def plot_uncertainties(x, y, nbins, minval, maxval):\n",
    "    \n",
    "    nbins\n",
    "    df_train, cuts1, cuts2 = ewd(x, y, nbins)\n",
    "    length = len(df_train[:,0])\n",
    "    mean, std, count = binned_statistics(x,y,nbins)\n",
    "\n",
    "    ## Plot the output\n",
    "    plt.errorbar(np.linspace(minval, maxval, nbins), mean, yerr = std, linestyle=':', marker='.', mfc='red', label='Mean and std')\n",
    "    plt.title('Binned means and std')\n",
    "    \n",
    "def plot_relative_error(x, y, nbins, minval, maxval):\n",
    "    df_train, cuts1, cuts2 = ewd(x, y)\n",
    "    length = len(df_train[:,0])\n",
    "    mean, std, count = binned_statistics(x,y)\n",
    "    \n",
    "    rel_error = np.divide(std, mean)\n",
    "    ax2 = plt.twinx()\n",
    "    \n",
    "    ax2.plot(np.linspace(minval, maxval, nbins), rel_error, 'x', color='gold',  label='Relative error')\n",
    "    plt.ylim([0,0.5])\n",
    "    \n",
    "\n",
    "def plot_smoothing(x,y,nbins,minval,maxval):\n",
    "    nbins\n",
    "    df_train, cuts1, cuts2 = ewd(x, y)\n",
    "    length = len(df_train[:,0])\n",
    "    mean, std, count = binned_statistics(x,y)\n",
    "\n",
    "    ## Plot the output\n",
    "    plt.errorbar(np.linspace(minval, maxval, nbins), mean, yerr = std, linestyle=':', marker='.',\n",
    "                  mfc='red')\n",
    "    plt.plot(np.linspace(minval, maxval, length))\n",
    "    plt.title('Binned means and std')\n",
    "    \n",
    "\"\"\"Neural network functions: \"\"\"\n",
    "    \n",
    "def custom_cost(y_true, y_pred):\n",
    "    '''Chi square function'''\n",
    "    return tf.reduce_mean(tf.square((y_true-y_pred)/sigma))\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def bootstrap():\n",
    "    df_train_a, df_train_b = train_test_split(df_train, test_size=0.5)\n",
    "    df_train_1, df_train_2 = train_test_split(df_train_a, test_size=0.5)\n",
    "    df_train_3, df_train_4 = train_test_split(df_train_b, test_size=0.5)\n",
    "    \n",
    "    return df_train_1, df_train_2, df_train_3, df_train_4\n",
    "    \n",
    "    \n",
    "def smooth(x,window_len=10,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    \n",
    "    index = int(window_len/2)\n",
    "    return y[(index-1):-(index)]\n",
    "\n",
    "def gaussian(x, amp, cen, std):\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    y = (amp) * np.exp(-(x-cen)**2 / (2*std**2))\n",
    "    return y\n",
    "\n",
    "    \n",
    "def window(x,y, minval, maxval):\n",
    "    \"\"\"Function applies a window to arrow\"\"\"\n",
    "    \n",
    "    low = next(i for i, val in enumerate(x) if val > minval)\n",
    "    treshold_min = str(low)\n",
    "    treshold_min = int(treshold_min)\n",
    "    up = next(i for i, val in enumerate(x) if val > maxval)\n",
    "    treshold_max = str(up)\n",
    "    treshold_max = int(treshold_max)\n",
    "    x = x[treshold_min:treshold_max]\n",
    "    y = y[treshold_min:treshold_max]\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def select_training_data(time):\n",
    "    \n",
    "    x_train, y_train, x_val, y_val = prepare_mix_data(time)\n",
    "    df_train, cuts1_t, cuts2_t = ewd(x_train, y_train)\n",
    "    mean_t, std_t, count_t= binned_statistics(x_train, y_train)\n",
    "    variance_vector_t = vectorize_variance(x_train, y_train)\n",
    "    mean_vector_t = vectorize_mean(x_train, y_train)\n",
    "    \n",
    "    #create one vector with (x_train, y_train, sigma_train)\n",
    "    df_train = np.c_[df_train, variance_vector_t]\n",
    "    \n",
    "def select_validation_data(time):\n",
    "    \n",
    "    x_train, y_train, x_val, y_val = prepare_mix_data(time)\n",
    "    df_val, cuts1_v, cuts2_v = ewd(x_val, y_val)\n",
    "    mean_v, std_v, count_v= binned_statistics(x_val, y_val)\n",
    "    variance_vector_v = vectorize_variance(x_val, y_val)\n",
    "    mean_vector_v = vectorize_mean(x_val, y_val)\n",
    "    #create one vector with (x_train, y_train, sigma_train)\n",
    "    df_val = np.c_[df_val, variance_vector_v]\n",
    "    \n",
    "    \n",
    "def add_time_energy(x, ms, energy):\n",
    "    \"\"\"Function that adds second input dimension for exposure time\"\"\"\n",
    "    time = np.array(ms)\n",
    "    energy = np.array(energy)\n",
    "    N_train = len(x[:,0])\n",
    "\n",
    "    train_x_a = copy(x[:,0]).reshape(N_train,1)  ## Column 1 = Eloss, colum 2 = time (binary)\n",
    "    train_x_time = train_x_a*0 + int(time)\n",
    "    train_x_energy = train_x_a*0 + int(energy)\n",
    "    train_x = np.c_[copy(x[:,0]), train_x_time, train_x_energy] \n",
    "    return train_x\n",
    "\n",
    "def residuals(prediction, y, std):\n",
    "    res = np.divide((prediction - y), std)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

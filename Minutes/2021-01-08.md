* We discussed the new python code that reads and processes .dm3 spectral images

* The code works as it should in that it reads the whole spectral images (as a proof of concept we are using the same image used in Laurien's paper) and produces a number of related images: a thickness image (each pixel indicates the thickness of the sample at this point, obtained from the EEL spectrum after ZLP subtraction), the number and position of crossings of the dielectric function, and other related information. This is done using the deconvolution procedure that we already benchmarked extensively with HyperSpy

* One problem is that the current ZLP models are not very good when comparing with most of the spectra from the image: a new batch of trainings is essential. For this, we will cluster the pixels into subsets of relatively similar thickness (between 3 and five clusters) and redo the NN training using the pseudo-data constructed from those spectra using EELSfitter

* We agreed that in the next days Isabel will put together some slides with the original spectral image and then with the heat maps that can be extracted from it (thickness, dielectric function etc). These heat maps will indicate the physical location in the image (in nm) rather than the bin index, which is internal information.

* For the clustering of the pixels, we can use k-means clustering or other similar unsupervised learning method, but we need to think carefully about the specific choice of distance.

* A good proxy for the thickness is the (inverse) of the integrated intensity, so we might want to use this for the clustering. Recall that I_0 is dampened exponentially with the thickness of the sample, while I_n/I_0 grows as t^n (but we know that for our relatively think samples the effects of the higher-order scatterings are small)

* Whatever method we use for the clustering of the individual spectra, 

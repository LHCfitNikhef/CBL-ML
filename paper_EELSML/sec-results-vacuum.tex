\section{Application to vacuum spectra}
\label{sec:results_vacuum}

Now we move to present the application of the strategy presented in the previous
section to the parametrisation of the ZLP spectra taken in vacuum.
%
Applying our model to this case has a two-fold motivation.
%
First of all, we aim to demonstrate that our model is flexible enough to effectively reproduce the
input EELS measurements for a range of variations of the operation parameters of the microscope.
%
Second, it will allow us to provide a calibration prediction for the case of the in-sample measurements.
%
Such calibration is necessary since, as explained in Sect.~\ref{sec:training}, some of the model
hyper-parameters are determined by the comparison of the intensity derivatives
between spectra taken in vacuum and those in sample.

%
For the ML model of the ZLP, four different sets of vacuum recordings
have been used, each measured under a different setting of exposure time 
and beam current. 
%
The data sets were recorded with a Titan TEM, equipped with a Skottky field emitter.
A maximum energy resolution (FWHM) of 0.003 eV could be realized. 
%
Table~\ref{table:vacuumdata} below indicates for each of the data sets the number of data files, 
the energy loss range, maximum recorded intensity and FWHM. 
%
These four data sets have been used to construct a ML-based
multidimensional model of the ZLP which can be inter- and extrapolated
to other operation conditions of the microscope.

In Table~\ref{table:vacuumdata} we collect the main properties of the EELS spectra acquired in vacuum to train the neural
    network model.  For each set of spectra, we indicate the exposure time $t_{\rm exp}$, the beam energy
    $E_b$, the number of spectra $N_{\rm sp}$ corresponding to these operation conditions, the number $N_{\rm dat}$ of
    bins in each spectrum, the range in electron energy loss $\Delta E$,
    and the average full width at half maximum (FWHM)
    evaluated over the $N_{\rm sp}$ spectra with the corresponding variance.
    %
    Since we are interested in the low-loss region, $\Delta E_{\rm max}$ does not need
    to be too large, and in any case the large $|\Delta E|$ behaviour of the model is fixed
    by the constraint implemented by means of Eq.~(\ref{eq:chi2modified}).
    %
    The energy resolution of these spectra, quantified by the value of the FWHM, ranges
    from 3 eV to 25 eV depending on the specific operation conditions of the microscope.
    %
    A total of 81920 independent measurements will be thus used for the ZLP model
    training on the vacuum spectra.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
  \begin{center}
            \renewcommand{\arraystretch}{1.50}
  \begin{tabular}{@{}ccccccccc}
\br
Set & $t_{\rm exp}$ {(}ms{)} & $E_{\rm b}$ {(}keV{)} & $N_{\rm sp}$ & $N_{\rm dat}$ & $\Delta E_{\rm min}$~(eV)  & $\Delta E_{\rm max}$~(eV)  & FWHM~(eV)  \\ 
\mr
1        & 100                 & 200                  & 15          & 2048               & -0.96              & 8.51     & $0.025\pm$         \\
2        & 100                 & 60                   & 7           & 2048               & -0.54              & 5.59    & $ 0.022\pm$         \\
3        & 10                  & 200                  & 12          & 2048               & -0.18              & 2.97      & $0.003\pm$         \\
4        & 10                  & 60                   & 6           & 2048               & -0.40              & 4.78       & $0.017\pm$         \\ 
\br
  \end{tabular}
    \end{center}
  \caption{\small Summary of the main properties of the EELS spectra acquired in vacuum to train the neural
    network model.  For each set of spectra, we indicate the exposure time $t_{\rm exp}$, the beam energy
    $E_b$, the number of spectra $N_{\rm sp}$ corresponding to these operation conditions, the number $N_{\rm dat}$ of
    bins in each spectrum, the range in electron energy loss $\Delta E$,
    and the average FWHM evaluated over the $N_{\rm sp}$ spectra with the corresponding variance.
  }
   \label{table:vacuumdata}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\subsection{High-dimensional ZLP prediction}
Thanks to the model independence of our approach, we have been able to assemble a high-dimensionality ML model
with multiple inputs to model the ZLP spectra. Extrapolating them 
to other operation conditions of the microscope beyond those included
in the training dataset yields reliable results, as to be discussed in this section.
The key feature of this new ZLP modeling method is that it strives to reveal the true dynamics of the situation: it takes in data and returns the predictions that describe the underlying physics. \\

After training the neural network $N_{rep}$ times on correspondingly many MC pseudo data sets, the best network parametrizations were retrieved to make predictions while interpolating and extrapolating on the training inputs. 

\subsubsection{Energy loss}
\label{sec:eloss}

The full energy range of the vacuum recorded peaks covers an interval varying from -1 to +9 eV. In order to test the flexibility of the network with respect to extrapolation on the energy interval, a window was applied to restrict the training loss values to [-0.2, 0.05] eV. Prediction inputs for exposure time and beam energy were kept the same as training values; the energy loss was extrapolated between [-0.5, 0.5] eV. After training the neural network on each MC replica, the best network parametrization was stored and used later for the prediction, such that from the ensemble of predictions the central values and uncertainties could be calculated. The results for the four different vacuum peaks can be observed in Fig.~\ref{fig:extrapoleloss} below. 

\begin{figure}[H]
    \centering
    \includegraphics[width=120mm]{plots/extrapolate_energyloss.png}
    \caption{Energy loss extrapolation on vacuum peaks under four different recording settings (exposure time, beam energy). The data within the energy region [-.2, 0.05] eV is known to the network by training. Extrapolation predictions are shown outside this region, marked by the dashed lines.}
    \label{fig:extrapoleloss}
\end{figure}

The goodness of our prediction can be quantified by means of $\chi^2$. So one can separate the parameter space (in Texp and Ebeam for example) into "training" and "prediction" regions, and use one to predict the other. If our error estimate is good, we should find chi2/ndat $\simeq$ 1 also for the predicted datasets


\subsubsection{Beam energy}
\label{sec:ebeam}
The training data contained only two recorded beam energies of 60 and 200 keV. Interpolation and extrapolation predictions have been retrieved on a continuous set of beam energies between 0 and 300 keV. In Fig.~\ref{fig:extrapolbeam} one can observe the mean predicted intensity and mean prediction error, where the average is taken over the energy loss range. The dashed lines indicate the beam energies for which we have data: correspondingly, the errors in these points are small, as the model can make an accurate prediction. The more the beam energy deviates from the known values, the bigger the uncertainties in the predictions become. 

\begin{figure}[H]
    \centering
    \includegraphics[width=120mm]{plots/Extrapolate_beamenergy.png}
    \caption{Predictions on a continuous set of beam energies, while inputs for energy loss and exposure time are the same as for the training data. The dashed lines indicate the beam energies that are known to the network by training.}
    \label{fig:extrapolbeam}
\end{figure}

\subsubsection{Exposure time}
\label{sec:texp}
The network was trained on data with exposure times of $10$ and $100$ ms, so interpolation and extrapolation is possible. Similar to the predictions for varying beam energy, also for exposure time the uncertainties grow bigger as the value deviates more from the training inputs.

\begin{figure}[H]
    \centering
    \includegraphics[width=120mm]{plots/Extrapolate_exposuretime.png}
    \caption{Predictions on a continuous set of exposure time, while inputs for energy loss and beam energy are the same as for the training data. The dashed lines indicate the exposure times known to the network by training.}
    \label{fig:extrapolbeam}
\end{figure}
